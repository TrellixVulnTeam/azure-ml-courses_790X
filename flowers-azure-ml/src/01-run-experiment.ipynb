{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azureml\n",
        "import shutil\n",
        "\n",
        "from azureml.core.authentication import AzureCliAuthentication\n",
        "from azureml.core import Workspace, Datastore, Experiment, Environment, ScriptRunConfig\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute, ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "\n",
        "# check core SDK version number\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure ML SDK Version:  1.41.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cli_auth = AzureCliAuthentication()\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=\"d752c461-4a37-4d63-a15d-ec58b07063cb\",\n",
        "    resource_group=\"ml-poc\",\n",
        "    workspace_name=\"ml-poc-ws\",\n",
        "    auth=cli_auth,\n",
        ")\n",
        "\n",
        "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found workspace ml-poc-ws at location westeurope\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_name = \"cc-shared-nc4-T4-v3\"\n",
        "compute_target = None\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        compute_target.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print(\"Compute Target:\", compute_target.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\nCompute Target: cc-shared-nc4-T4-v3\n"
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the datastore for the training images\n",
        "ds = Datastore.get_default(ws)\n",
        "print(\"Datastore:\", ds.name)\n",
        "\n",
        "# Get access to Flowers dataset\n",
        "flowers_ds = Dataset.get_by_name(ws, name='flowers-dataset')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore: workspaceblobstore\n"
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the experiment\n",
        "exp = Experiment(workspace=ws, name='flowers-clf-experiment')\n",
        "print(\"Experiment:\", exp.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Experiment: flowers-clf-experiment\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model & Publish training pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'flowers-train-pytorch-1-10-ubuntu18-py38-cuda11-gpu'\n",
        "pytorch_env = Environment.get(workspace=ws, name=env_name)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the training pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "pipeline_run_config = RunConfiguration()\n",
        "pipeline_run_config.target = compute_target\n",
        "pipeline_run_config.environment = pytorch_env\n",
        "\n",
        "args = [\n",
        "    '--data-folder', flowers_ds.as_named_input('flowers').as_mount(),\n",
        "]\n",
        "\n",
        "project_folder = \"./\"\n",
        "\n",
        "train_step = PythonScriptStep(\n",
        "    name=\"Train flowers model\",\n",
        "    source_directory=project_folder,\n",
        "    script_name=\"train.py\",\n",
        "    arguments=args,\n",
        "    compute_target=compute_target,\n",
        "    runconfig=pipeline_run_config,\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_pipeline_steps = [train_step]\n",
        "train_pipeline = Pipeline(workspace=ws, steps=train_pipeline_steps)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# args = [\n",
        "#     '--data-folder', flowers_ds.as_named_input('flowers').as_mount(),\n",
        "# ]\n",
        "\n",
        "# project_folder = \"./\"\n",
        "\n",
        "# config = ScriptRunConfig(\n",
        "#     source_directory=project_folder, \n",
        "#     script='train.py', \n",
        "#     compute_target=compute_target,\n",
        "#     environment=pytorch_env,\n",
        "#     arguments=args,\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run = exp.submit(train_pipeline, regenerate_outputs=True)\n",
        "RunDetails(pipeline_run).show()\n",
        "# pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Train flowers model [39d379a1][cb1f0157-cd3f-4114-824f-46a27d6d5ace], (This step will run and generate new outputs)\nSubmitted PipelineRun ce7edf44-5d25-4020-a4b9-9932cf82668e\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/ce7edf44-5d25-4020-a4b9-9932cf82668e?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&tid=9064dc66-330c-438e-aee3-1c9e605cc16d\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c57e26f8e52444c80972300f4444d0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/ce7edf44-5d25-4020-a4b9-9932cf82668e?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&tid=9064dc66-330c-438e-aee3-1c9e605cc16d\", \"run_id\": \"ce7edf44-5d25-4020-a4b9-9932cf82668e\", \"run_properties\": {\"run_id\": \"ce7edf44-5d25-4020-a4b9-9932cf82668e\", \"created_utc\": \"2022-05-26T20:06:52.990374Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-05-26T20:49:22.914014Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.ce7edf44-5d25-4020-a4b9-9932cf82668e/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=M9vybT4c%2BhtGngXHNkfAKXawteX1TalyaTU9l4vpzHE%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T20%3A50%3A16Z&se=2022-05-27T05%3A00%3A16Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.ce7edf44-5d25-4020-a4b9-9932cf82668e/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=n7oSPPmCSAcub4UdQ7DRZ1WKD8ME19eNcF%2Bi3WTpANg%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T20%3A50%3A16Z&se=2022-05-27T05%3A00%3A16Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.ce7edf44-5d25-4020-a4b9-9932cf82668e/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=fJXME7oFjsvYvNK8tnn%2BPOS64AVwJM0EemUsRl8Fm10%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T20%3A50%3A16Z&se=2022-05-27T05%3A00%3A16Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:42:29\", \"run_number\": \"1653595613\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"3a9947a6-27a6-4f26-86d4-1593086f4988\", \"name\": \"Train flowers model\", \"status\": \"Finished\", \"start_time\": \"2022-05-26T20:11:12.350178Z\", \"created_time\": \"2022-05-26T20:06:55.343502Z\", \"end_time\": \"2022-05-26T20:49:21.665967Z\", \"duration\": \"0:42:26\", \"run_number\": 1653595615, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-05-26T20:06:55.343502Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-05-26 20:06:55Z] Submitting 1 runs, first five are: 39d379a1:3a9947a6-27a6-4f26-86d4-1593086f4988\\n[2022-05-26 20:49:22Z] Completing processing run id 3a9947a6-27a6-4f26-86d4-1593086f4988.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"60153a8c\": {\"node_id\": \"60153a8c\", \"name\": \"flowers-dataset\"}}, \"module_nodes\": {\"39d379a1\": {\"node_id\": \"39d379a1\", \"name\": \"Train flowers model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"3a9947a6-27a6-4f26-86d4-1593086f4988\"}}, \"edges\": [{\"source_node_id\": \"60153a8c\", \"source_node_name\": \"flowers-dataset\", \"source_name\": \"data\", \"target_name\": \"flowers\", \"dst_node_id\": \"39d379a1\", \"dst_node_name\": \"Train flowers model\"}], \"child_runs\": [{\"run_id\": \"3a9947a6-27a6-4f26-86d4-1593086f4988\", \"name\": \"Train flowers model\", \"status\": \"Finished\", \"start_time\": \"2022-05-26T20:11:12.350178Z\", \"created_time\": \"2022-05-26T20:06:55.343502Z\", \"end_time\": \"2022-05-26T20:49:21.665967Z\", \"duration\": \"0:42:26\", \"run_number\": 1653595615, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-05-26T20:06:55.343502Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.41.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>flowers-clf-experiment</td><td>ce7edf44-5d25-4020-a4b9-9932cf82668e</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/ce7edf44-5d25-4020-a4b9-9932cf82668e?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&amp;tid=9064dc66-330c-438e-aee3-1c9e605cc16d\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: flowers-clf-experiment,\nId: ce7edf44-5d25-4020-a4b9-9932cf82668e,\nType: azureml.PipelineRun,\nStatus: Completed)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show info about metrics and models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    if not model.name.startswith('Flowers-clf-PyTorch'):\n",
        "        continue\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Flowers-clf-PyTorch version: 3\n\t Training context : Pipeline\n\n\nFlowers-clf-PyTorch version: 2\n\n\nFlowers-clf-PyTorch version: 1\n\n\n"
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the model in Azure ML"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# model = pipeline_run.register_model(\n",
        "#     model_name='Flowers-clf-PyTorch',\n",
        "#     model_path='outputs/models/FlowersConvModel_model_best.pth',\n",
        "#     description=\"Flowers PyTorch Classifier\",\n",
        "#     resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=2)\n",
        "# )\n",
        "\n",
        "# print(\"Model '{}' version {} registered \".format(model.name, model.version))"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Publish training pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name='flowers-train-pipeline', description='Train flowers model', version='1.0'\n",
        ")\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>flowers-train-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/c0fdd530-63af-4656-9dfc-8f769bfbec4a?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws\" target=\"_blank\" rel=\"noopener\">c0fdd530-63af-4656-9dfc-8f769bfbec4a</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourceGroups/ml-poc/providers/Microsoft.MachineLearningServices/workspaces/ml-poc-ws/PipelineRuns/PipelineSubmit/c0fdd530-63af-4656-9dfc-8f769bfbec4a\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>",
            "text/plain": "Pipeline(Name: flowers-train-pipeline,\nId: c0fdd530-63af-4656-9dfc-8f769bfbec4a,\nStatus: Active,\nEndpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourceGroups/ml-poc/providers/Microsoft.MachineLearningServices/workspaces/ml-poc-ws/PipelineRuns/PipelineSubmit/c0fdd530-63af-4656-9dfc-8f769bfbec4a)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourceGroups/ml-poc/providers/Microsoft.MachineLearningServices/workspaces/ml-poc-ws/PipelineRuns/PipelineSubmit/c0fdd530-63af-4656-9dfc-8f769bfbec4a\n"
        }
      ],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish inference pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'flowers-infer-pytorch-1-10-ubuntu18-py38-cuda11-gpu'\n",
        "pytorch_env = Environment.get(workspace=ws, name=env_name)"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a compute target"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_name = \"cc-shared-nc4-T4-v3\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        inference_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 32,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a infer pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
        "from azureml.data import OutputFileDatasetConfig"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = OutputFileDatasetConfig(name='inferences')\n",
        "\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    source_directory='./',\n",
        "    entry_script=\"infer_batch.py\",\n",
        "    mini_batch_size=\"5\",\n",
        "    error_threshold=10,\n",
        "    output_action=\"append_row\",\n",
        "    environment=pytorch_env,\n",
        "    compute_target=inference_cluster,\n",
        "    node_count=1\n",
        ")\n",
        "\n",
        "parallelrun_step = ParallelRunStep(\n",
        "    name='flowers-batch-score',\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    inputs=[flowers_ds.as_named_input('flowers').as_mount()],\n",
        "    output=output_dir,\n",
        "    arguments=[],\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 34,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
        "pipeline_run = Experiment(ws, 'flowers-infer-batch').submit(pipeline)\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step flowers-batch-score [0d4b2959][85dfb5f8-2d2a-4892-8916-c325d4d12438], (This step will run and generate new outputs)\nSubmitted PipelineRun aa2eb0e7-a05c-4d39-8564-49a5985a2f4e\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/aa2eb0e7-a05c-4d39-8564-49a5985a2f4e?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&tid=9064dc66-330c-438e-aee3-1c9e605cc16d\nPipelineRunId: aa2eb0e7-a05c-4d39-8564-49a5985a2f4e\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/aa2eb0e7-a05c-4d39-8564-49a5985a2f4e?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&tid=9064dc66-330c-438e-aee3-1c9e605cc16d\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: dd187426-e4bc-408a-af1d-72d71612c29b\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/dd187426-e4bc-408a-af1d-72d71612c29b?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&tid=9064dc66-330c-438e-aee3-1c9e605cc16d\nStepRun( flowers-batch-score ) Status: NotStarted\nStepRun( flowers-batch-score ) Status: Queued\nStepRun( flowers-batch-score ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt\n========================================================================================================================\n2022-05-26T15:15:21Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=162729 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-05-26T15:15:22Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/mounts/workspaceblobstore -- stdout/stderr: \n2022-05-26T15:15:22Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n. Please ignore this if the GPUs don't utilize NVIDIAÂ® NVLinkÂ® switches.\n2022-05-26T15:15:22Z Starting output-watcher...\n2022-05-26T15:15:22Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n2022-05-26T15:15:22Z Executing 'Copy ACR Details file' on 10.0.0.5\n2022-05-26T15:15:22Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a\ne0b25ef51634: Pulling fs layer\n7b13e9939f7b: Pulling fs layer\n807ec43292c9: Pulling fs layer\n94f0b2b47a7c: Pulling fs layer\nbd6e09d7d402: Pulling fs layer\nb3757b0f5de5: Pulling fs layer\na106ee428b15: Pulling fs layer\nbc7243f99ccc: Pulling fs layer\ndbab89f33283: Pulling fs layer\n92da08bb365d: Pulling fs layer\nf4ba2934c358: Pulling fs layer\nc243525e6e96: Pulling fs layer\nd21180aff2a5: Pulling fs layer\n41090c6d20f3: Pulling fs layer\na2a9d72f89af: Pulling fs layer\n7e37e66c429d: Pulling fs layer\n74a3275e7926: Pulling fs layer\ne44d48a68272: Pulling fs layer\ndd4e7abe539c: Pulling fs layer\ndbab89f33283: Waiting\n92da08bb365d: Waiting\nf4ba2934c358: Waiting\nc243525e6e96: Waiting\nd21180aff2a5: Waiting\n41090c6d20f3: Waiting\na2a9d72f89af: Waiting\n7e37e66c429d: Waiting\n74a3275e7926: Waiting\nbd6e09d7d402: Waiting\ne44d48a68272: Waiting\ndd4e7abe539c: Waiting\nb3757b0f5de5: Waiting\na106ee428b15: Waiting\n94f0b2b47a7c: Waiting\nbc7243f99ccc: Waiting\n807ec43292c9: Verifying Checksum\n807ec43292c9: Download complete\ne0b25ef51634: Verifying Checksum\ne0b25ef51634: Download complete\n94f0b2b47a7c: Download complete\nb3757b0f5de5: Verifying Checksum\nb3757b0f5de5: Download complete\na106ee428b15: Verifying Checksum\na106ee428b15: Download complete\ne0b25ef51634: Pull complete\nbc7243f99ccc: Verifying Checksum\nbc7243f99ccc: Download complete\ndbab89f33283: Verifying Checksum\ndbab89f33283: Download complete\n7b13e9939f7b: Verifying Checksum\n7b13e9939f7b: Download complete\n92da08bb365d: Verifying Checksum\n92da08bb365d: Download complete\nf4ba2934c358: Verifying Checksum\nf4ba2934c358: Download complete\nd21180aff2a5: Verifying Checksum\nd21180aff2a5: Download complete\n41090c6d20f3: Verifying Checksum\n41090c6d20f3: Download complete\na2a9d72f89af: Verifying Checksum\na2a9d72f89af: Download complete\n7e37e66c429d: Download complete\n74a3275e7926: Verifying Checksum\n74a3275e7926: Download complete\ne44d48a68272: Verifying Checksum\ne44d48a68272: Download complete\ndd4e7abe539c: Verifying Checksum\ndd4e7abe539c: Download complete\nc243525e6e96: Verifying Checksum\nc243525e6e96: Download complete\n7b13e9939f7b: Pull complete\n807ec43292c9: Pull complete\n94f0b2b47a7c: Pull complete\nbd6e09d7d402: Verifying Checksum\nbd6e09d7d402: Download complete\nbd6e09d7d402: Pull complete\nb3757b0f5de5: Pull complete\na106ee428b15: Pull complete\nbc7243f99ccc: Pull complete\ndbab89f33283: Pull complete\n92da08bb365d: Pull complete\nf4ba2934c358: Pull complete\nc243525e6e96: Pull complete\nd21180aff2a5: Pull complete\n41090c6d20f3: Pull complete\na2a9d72f89af: Pull complete\n7e37e66c429d: Pull complete\n74a3275e7926: Pull complete\ne44d48a68272: Pull complete\ndd4e7abe539c: Pull complete\nDigest: sha256:827f6aea3b77adba06a985afe197787070432a1aaee0e5b7ae3fb65a90c602e3\nStatus: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a:latest\nviennaglobal.azurecr.io/azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a:latest\n2022-05-26T15:16:35Z Check if container dd187426-e4bc-408a-af1d-72d71612c29b_DataSidecar already exist exited with 0, \n\ne694af684bd4f9fa31359bb8ee5cf2f87c5b0dea0daebf91859920b2153bc74d\n2022-05-26T15:16:36Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-05-26T15:16:36Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-571236ac676e3a9efd41986f00bbd3ee-a95bbe121090471b-01 -sshRequired=false] \n2022/05/26 15:16:36 Didn't get JobInfoJson from env, now read from file\n2022/05/26 15:16:36 Suceeded read JobInfoJson from file\n2022/05/26 15:16:36 Starting App Insight Logger for task:  containerSetup\n2022/05/26 15:16:36 Version: 3.0.01968.0004 Branch: hotfix-release-198 Commit: 5c02518\n2022/05/26 15:16:36 Entered ContainerSetupTask - Preparing infiniband\n2022/05/26 15:16:36 Starting infiniband setup\n2022/05/26 15:16:36 Python Version found is Python 3.7.9\n\n2022/05/26 15:16:36 Returning Python Version as 3.7\n2022-05-26T15:16:36Z VMSize: standard_nc4as_t4_v3, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/05/26 15:16:36 VMSize: standard_nc4as_t4_v3, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/05/26 15:16:36 VMSize: standard_nc4as_t4_v3, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/05/26 15:16:36 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022/05/26 15:16:36 Not setting up Infiniband in Container\n2022-05-26T15:16:36Z Not setting up Infiniband in Container\n2022/05/26 15:16:36 Not setting up Infiniband in Container\n2022/05/26 15:16:36 Python Version found is Python 3.7.9\n\n2022/05/26 15:16:36 Returning Python Version as 3.7\n2022/05/26 15:16:36 sshd inside container not required for job, skipping setup.\n2022/05/26 15:16:36 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/05/26 15:16:36 App Insight Client has already been closed\n2022/05/26 15:16:36 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-05-26T15:16:36Z Starting docker container succeeded.\n\nStreaming azureml-logs/65_job_prep-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt\n===============================================================================================================\n[2022-05-26T15:16:38.416223] Entering job preparation.\n[2022-05-26T15:16:38.997551] Starting job preparation.\n[2022-05-26T15:16:38.997581] Extracting the control code.\n[2022-05-26T15:16:38.997816] Starting extract_project.\n[2022-05-26T15:16:38.997844] Starting to extract zip file.\n[2022-05-26T15:16:39.020348] Finished extracting zip file.\n[2022-05-26T15:16:39.027783] Using urllib.request Python 3.0 or later\n[2022-05-26T15:16:39.027812] Start fetching snapshots.\n[2022-05-26T15:16:39.027835] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 52\n[2022-05-26T15:16:40.492029] Finished fetching snapshot.\n[2022-05-26T15:16:40.492067] Start fetching snapshot.\n[2022-05-26T15:16:47.614457] Finished fetching snapshot.\n[2022-05-26T15:16:47.614494] Finished fetching snapshots.\n[2022-05-26T15:16:47.614499] Finished extract_project.\n[2022-05-26T15:16:47.614562] Finished fetching and extracting the control code.\n[2022-05-26T15:16:47.618679] Start run_history_prep.\n[2022-05-26T15:16:47.622049] Job preparation is complete.\n[2022-05-26T15:16:47.622122] Entering Data Context Managers in Sidecar\n[2022-05-26T15:16:47.622598] Running Sidecar prep cmd...\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-05-26T15:16:47.958956] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/azureml/dd187426-e4bc-408a-af1d-72d71612c29b\n[2022-05-26T15:16:47.959425] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2022-05-26T15:16:48.022] Enter __enter__ of DatasetContextManager\n[2022-05-26T15:16:48.023] SDK version: azureml-core==1.41.0.post1 azureml-dataprep==3.1.2. Session id: 9789ce90-7c95-4ebd-98db-8b45105a0e65. Run id: dd187426-e4bc-408a-af1d-72d71612c29b.\n[2022-05-26T15:16:48.023] Processing 'flowers'.\n[2022-05-26T15:16:48.023] Mode: 'mount'.\n[2022-05-26T15:16:48.023] Path on compute is specified: 'False'.\n[2022-05-26T15:16:48.023] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: flowers\n[2022-05-26T15:16:50.211] Processing dataset FileDataset\n{\n  \"source\": [\n    \"('workspaceblobstore', 'flowers/05-20-2022_084821_UTC/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"62f3ee6e-7d83-4708-86ab-7e1ef4b831ff\",\n    \"name\": \"flowers-dataset\",\n    \"version\": 1,\n    \"workspace\": \"Workspace.create(name='ml-poc-ws', subscription_id='d752c461-4a37-4d63-a15d-ec58b07063cb', resource_group='ml-poc')\"\n  }\n}\n[2022-05-26T15:16:51.049] Mounting flowers to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/flowers_62f3ee6e-7d83-4708-86ab-7e1ef4b831ff as folder.\n[2022-05-26T15:16:51.049] Processing 'inferences'.\n[2022-05-26T15:16:51.049] Mode: 'mount'.\n[2022-05-26T15:16:51.049] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore'.\n[2022-05-26T15:16:51.174] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore\n[2022-05-26T15:16:51.174] Output is not a single file\n[2022-05-26T15:16:51.174] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore as folder\n[2022-05-26T15:16:51.605] Mounting flowers to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/flowers_62f3ee6e-7d83-4708-86ab-7e1ef4b831ff.\n[2022-05-26T15:16:52.605] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore.\n[2022-05-26T15:16:52.606] Mounted flowers to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/flowers_62f3ee6e-7d83-4708-86ab-7e1ef4b831ff.\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-05-26T15:16:55.656] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore.\n[2022-05-26T15:16:55.717] Exit __enter__ of DatasetContextManager\nuri entered in sidecar: None\nSet Dataset flowers's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/flowers_62f3ee6e-7d83-4708-86ab-7e1ef4b831ff\nSet OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore\n[2022-05-26T15:16:55.718015] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2022-05-26T15:16:56.455088] Ran Sidecar prep cmd.\n[2022-05-26T15:16:56.455167] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2022/05/26 15:24:33 Didn't get JobInfoJson from env, now read from file\n2022/05/26 15:24:33 Suceeded read JobInfoJson from file\n2022/05/26 15:24:33 Starting App Insight Logger for task:  runTaskLet\n2022/05/26 15:24:33 Version: 3.0.01968.0004 Branch: hotfix-release-198 Commit: 5c02518\n2022/05/26 15:24:33 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n2022/05/26 15:24:33 Send process info logs to master server succeeded\n2022/05/26 15:24:33 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n2022/05/26 15:24:33 Send process info logs to master server succeeded\n[2022-05-26T15:24:33.117846] Entering context manager injector.\n[2022-05-26T15:24:33.514634] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.41.0', '--scoring_module_name', 'infer_batch.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'flowers'])\nScript type = None\n[2022-05-26T15:24:33.517769] Entering Run History Context Manager.\n[2022-05-26T15:24:35.359247] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/azureml/dd187426-e4bc-408a-af1d-72d71612c29b\n[2022-05-26T15:24:35.359379] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.41.0', '--scoring_module_name', 'infer_batch.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'flowers']\n[2022-05-26T15:24:35.359433] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.41.0', '--scoring_module_name', 'infer_batch.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore', '--input_fds_0', 'flowers']\n\n2022/05/26 15:24:38 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n\nStreaming azureml-logs/75_job_post-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt\n===============================================================================================================\n[2022-05-26T15:29:28.460106] Entering job release\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-05-26T15:29:29.125665] Starting job release\n[2022-05-26T15:29:29.126075] Logging experiment finalizing status in history service.[2022-05-26T15:29:29.126182] job release stage : upload_datastore starting...\n\nStarting the daemon thread to refresh tokens in background for process with pid = 425[2022-05-26T15:29:29.126429] job release stage : start importing azureml.history._tracking in run_history_release.\n\n[2022-05-26T15:29:29.126646] job release stage : execute_job_release starting...\n[2022-05-26T15:29:29.126833] job release stage : copy_batchai_cached_logs starting...\n[2022-05-26T15:29:29.130908] job release stage : copy_batchai_cached_logs completed...\n[2022-05-26T15:29:29.137325] Entering context manager injector.\n[2022-05-26T15:29:29.140908] job release stage : upload_datastore completed...\n[2022-05-26T15:29:29.217995] job release stage : send_run_telemetry starting...\n[2022-05-26T15:29:29.236077] get vm size and vm region successfully.\n[2022-05-26T15:29:29.241220] get compute meta data successfully.\n[2022-05-26T15:29:29.284781] job release stage : execute_job_release completed...\n[2022-05-26T15:29:29.501327] post artifact meta request successfully.\n[2022-05-26T15:29:29.544274] upload compute record artifact successfully.\n[2022-05-26T15:29:29.544308] job release stage : send_run_telemetry completed...\n[2022-05-26T15:29:29.544469] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-05-26T15:29:29.544582] Running Sidecar release cmd...\n[2022-05-26T15:29:29.553331] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/azureml/dd187426-e4bc-408a-af1d-72d71612c29b\n[2022-05-26T15:29:29.566] Enter __exit__ of DatasetContextManager\n[2022-05-26T15:29:29.566] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/flowers_62f3ee6e-7d83-4708-86ab-7e1ef4b831ff.\n[2022-05-26T15:29:30.571] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/flowers_62f3ee6e-7d83-4708-86ab-7e1ef4b831ff.\n[2022-05-26T15:29:30.571] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore.\nfuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore: Invalid argument\n[2022-05-26T15:29:30.582] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-poc-ws/azureml/dd187426-e4bc-408a-af1d-72d71612c29b/wd/inferences_workspaceblobstore.\n[2022-05-26T15:29:30.582] Exit __exit__ of DatasetContextManager\n[2022-05-26T15:29:30.582133] Removing absolute paths from host...\n[2022-05-26T15:29:30.582316] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-05-26T15:29:31.355835] Ran Sidecar release cmd.\n[2022-05-26T15:29:31.355891] Job release is complete\n\nStepRun(flowers-batch-score) Execution Summary\n===============================================\nStepRun( flowers-batch-score ) Status: Finished\n{'runId': 'dd187426-e4bc-408a-af1d-72d71612c29b', 'target': 'cc-shared-nc4-T4-v3', 'status': 'Completed', 'startTimeUtc': '2022-05-26T15:15:21.505493Z', 'endTimeUtc': '2022-05-26T15:29:39.345065Z', 'services': {}, 'properties': {'ContentSnapshotId': '0c64a0ab-60d5-45a4-a16d-558ac3572d40', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '85dfb5f8-2d2a-4892-8916-c325d4d12438', 'azureml.moduleName': 'flowers-batch-score', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '0d4b2959', 'azureml.pipelinerunid': 'aa2eb0e7-a05c-4d39-8564-49a5985a2f4e', 'azureml.pipeline': 'aa2eb0e7-a05c-4d39-8564-49a5985a2f4e', 'azureml.pipelineComponent': 'masterescloud', 'azureml.parallelrunstep': 'true', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '62f3ee6e-7d83-4708-86ab-7e1ef4b831ff'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'flowers', 'mechanism': 'Mount'}}], 'outputDatasets': [{'identifier': {'savedId': '7c5c060b-195d-472f-a6c9-76147b833ed5'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/dd187426-e4bc-408a-af1d-72d71612c29b/inferences/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"7c5c060b-195d-472f-a6c9-76147b833ed5\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='ml-poc-ws', subscription_id='d752c461-4a37-4d63-a15d-ec58b07063cb', resource_group='ml-poc')\"\n  }\n}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.41.0', '--scoring_module_name', 'infer_batch.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'flowers'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cc-shared-nc4-T4-v3', 'dataReferences': {}, 'data': {'flowers': {'dataLocation': {'dataset': {'id': '62f3ee6e-7d83-4708-86ab-7e1ef4b831ff', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'flowers', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': 'aa2eb0e7-a05c-4d39-8564-49a5985a2f4e', 'azureml.pipelineRun.moduleNodeId': '0d4b2959', 'azureml.pipelineRun.outputPortName': 'inferences'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'flowers-infer-pytorch-1-10-ubuntu18-py38-cuda11-gpu', 'version': '3', 'assetId': 'azureml://locations/westeurope/workspaces/113d745f-00bc-424d-8c14-d248b60a9683/environments/flowers-infer-pytorch-1-10-ubuntu18-py38-cuda11-gpu/versions/3', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.8', {'pip': ['psutil>=5.8,<5.9', 'tqdm>=4.59,<4.63', 'numpy>=1.10,<1.22', 'ipykernel~=6.0', 'azureml-core~=1.41.0', 'azureml-defaults~=1.41.0', 'azureml-mlflow~=1.41.0', 'azureml-telemetry~=1.41.0', 'onnxruntime-gpu>=1.7,<1.10', 'future==0.18.2', 'opencv-python==4.5.4.60', 'opencv-python-headless==4.5.5.64', 'albumentations==1.1.0', 'protobuf==3.20.0']}, 'pip==20.2.4', 'pytorch=1.10.0', 'torchvision=0.11.1', 'cudatoolkit=11.1.1', 'nvidia-apex=0.1.0', 'gxx_linux-64'], 'channels': ['anaconda', 'conda-forge', 'pytorch']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': '\\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20220516.v1\\n\\nRUN apt-get install ffmpeg libsm6 libxext6 libgl1-mesa-glx  -y\\nRUN apt-get update && apt-get install -y python3-opencv\\n', 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/azureml-logs/55_azureml-execution-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt?sv=2019-07-07&sr=b&sig=VIFmByBljaZcw3fb67Yicg0Xswmo%2F4ur2bB03wQ7Zpo%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'azureml-logs/65_job_prep-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/azureml-logs/65_job_prep-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt?sv=2019-07-07&sr=b&sig=zmtPe8N6tq86tTrMMzMqESmy8TR9E2T8Wbf3eY6pN9I%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=Xv3xNYAH%2BIUY3oFgun%2BawDTivyJKOd1lytBF5%2Bxd0uY%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'azureml-logs/75_job_post-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/azureml-logs/75_job_post-tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p.txt?sv=2019-07-07&sr=b&sig=LgIURDXo%2Frutn%2Fmjqbq%2FBsVIDepV8VZOMYKBKHNwQyY%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'azureml-logs/process_info.json': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=yiphrXikFJq36xow4Cx%2BvT8YgcGWUuitLxsOJ31GgME%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'azureml-logs/process_status.json': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=j2HIDBxneQWKPOnku3JSa02Rj3%2FRT7Z30uo%2F7zopVxw%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/79_azureml.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/79_azureml.log?sv=2019-07-07&sr=b&sig=COJYcAEvN6woUM%2FGhfOqpUXFNwu72LGMVNdPkO9fpjE%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=zOy%2BUFt8TJk%2F4feTpmDo%2FfonnB9QkeqotD2mdHtPfL8%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=uQFAGt9aQyN3qFs3GeyYaqOCHR%2Fa29DRAb6F%2Bpu7v%2B8%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=9OuEUws3TTOssB2px7rsQ%2BzhhdHD%2F4Nc4szM6JcxCy4%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=58uusYS4hwbL8Q2M7tL2f8aXrvNOSWjQy6Z8miySKDg%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=YvEq37%2FyQfyDWnGtqEwCMsfOL1kwwcTuqlE9%2BVU8Quc%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/sidecar/tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p/all.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/sidecar/tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p/all.log?sv=2019-07-07&sr=b&sig=UYV20UCafZG97a2G7NOSPPXCOxTpA4%2B0%2FGCQflF27r4%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/sidecar/tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p/task.enter_contexts.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/sidecar/tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=jYjzeh00gqdzCnJJNf%2FFxuG9CNoVdi4fNjB9fktpNYE%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/sidecar/tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p/task.exit_contexts.log': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/sidecar/tvmps_619ed28f38d44584e8b16f33ca32a0814200734890c66ffcffeeaaf49f3318f6_p/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=xAgC7JgY4NtZecIl0jvCgZzWo%2FxqXBP73ByGTv746Xg%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=akkLZXAkodKQq30lGuGE4agKKFxqyNlRrXxQrymdnMw%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.dd187426-e4bc-408a-af1d-72d71612c29b/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=U4gqRMlFBnbzc3Gu3mCwpzpnqszLJxZmtoIxFVrIcBI%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A32Z&se=2022-05-26T23%3A29%3A32Z&sp=r'}, 'submittedBy': 'Roman Kryvokhyzha'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'aa2eb0e7-a05c-4d39-8564-49a5985a2f4e', 'status': 'Completed', 'startTimeUtc': '2022-05-26T15:10:01.271548Z', 'endTimeUtc': '2022-05-26T15:29:42.163534Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.aa2eb0e7-a05c-4d39-8564-49a5985a2f4e/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=TY2UwqD09CIpOnxPzTk1QIbuj3%2FzwkldWHfI3MU8kak%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A46Z&se=2022-05-26T23%3A29%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.aa2eb0e7-a05c-4d39-8564-49a5985a2f4e/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=mprYT48ZHzxmHOImeZMZI%2FyjYewAK3HftkUihXQdhSA%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A46Z&se=2022-05-26T23%3A29%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.aa2eb0e7-a05c-4d39-8564-49a5985a2f4e/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=89sJFXUlcgSFBPZxdt%2BzUf8y2BjH0o9J8kLw2DZn1co%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A19%3A46Z&se=2022-05-26T23%3A29%3A46Z&sp=r'}, 'submittedBy': 'Roman Kryvokhyzha'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Remove the local results folder if left over from a previous run\n",
        "shutil.rmtree('../output/predictions', ignore_errors=True)\n",
        "\n",
        "# Get the run for the first step and download its output\n",
        "prediction_run = next(pipeline_run.get_children())\n",
        "prediction_output = prediction_run.get_output_data('inferences')\n",
        "prediction_output.download(local_path='../output/predictions')\n",
        "\n",
        "# Traverse the folder hierarchy and find the results file\n",
        "for root, dirs, files in os.walk('../output/predictions'):\n",
        "    for file in files:\n",
        "        if file.endswith('parallel_run_step.txt'):\n",
        "            result_file = os.path.join(root,file)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"File\", \"Prediction\"]\n",
        "\n",
        "# Display the first 20 results\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100080576_f52e8ee070_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10140303196_b88d3d6cec.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10172379554_b296050f82_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10172567486_2748826a8b.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102841525_bd6628ae3c.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10437754174_22ec990b77_m.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10437770546_8bb6f7bdd3_m.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10437929963_bc13eebe0c.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10466558316_a7198b87e2.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10555749515_13a12a026e.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10555815624_dc211569b0.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10555826524_423eb8bf71_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10559679065_50d2b16f6d.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>105806915_a9c13e2106_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>10712722853_5632165b04.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>107592979_aaa9cdfe78_m.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10770585085_4742b9dac3_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10841136265_af473efc60.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10993710036_2033222c91.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10993818044_4c19b86c82.jpg</td>\n      <td>[0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                            File Prediction\n0     100080576_f52e8ee070_n.jpg        [0]\n1     10140303196_b88d3d6cec.jpg        [0]\n2   10172379554_b296050f82_n.jpg        [0]\n3     10172567486_2748826a8b.jpg        [0]\n4       102841525_bd6628ae3c.jpg        [0]\n5   10437754174_22ec990b77_m.jpg        [0]\n6   10437770546_8bb6f7bdd3_m.jpg        [0]\n7     10437929963_bc13eebe0c.jpg        [0]\n8     10466558316_a7198b87e2.jpg        [0]\n9     10555749515_13a12a026e.jpg        [0]\n10    10555815624_dc211569b0.jpg        [0]\n11  10555826524_423eb8bf71_n.jpg        [0]\n12    10559679065_50d2b16f6d.jpg        [0]\n13    105806915_a9c13e2106_n.jpg        [0]\n14    10712722853_5632165b04.jpg        [0]\n15    107592979_aaa9cdfe78_m.jpg        [0]\n16  10770585085_4742b9dac3_n.jpg        [0]\n17    10841136265_af473efc60.jpg        [0]\n18    10993710036_2033222c91.jpg        [0]\n19    10993818044_4c19b86c82.jpg        [0]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name='flowers-infer-batch-pipeline', description='Batch scoring of flowers data', version='1.0'\n",
        ")\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>flowers-infer-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/caab782f-f3cb-458b-be04-5d53612f0e2b?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws\" target=\"_blank\" rel=\"noopener\">caab782f-f3cb-458b-be04-5d53612f0e2b</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourceGroups/ml-poc/providers/Microsoft.MachineLearningServices/workspaces/ml-poc-ws/PipelineRuns/PipelineSubmit/caab782f-f3cb-458b-be04-5d53612f0e2b\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>",
            "text/plain": "Pipeline(Name: flowers-infer-batch-pipeline,\nId: caab782f-f3cb-458b-be04-5d53612f0e2b,\nStatus: Active,\nEndpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourceGroups/ml-poc/providers/Microsoft.MachineLearningServices/workspaces/ml-poc-ws/PipelineRuns/PipelineSubmit/caab782f-f3cb-458b-be04-5d53612f0e2b)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourceGroups/ml-poc/providers/Microsoft.MachineLearningServices/workspaces/ml-poc-ws/PipelineRuns/PipelineSubmit/caab782f-f3cb-458b-be04-5d53612f0e2b\n"
        }
      ],
      "execution_count": 38,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print('Authentication header ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(\n",
        "    rest_endpoint, \n",
        "    headers=auth_header, \n",
        "    json={\"ExperimentName\": \"flowers-infer-batch\"}\n",
        ")\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "'c638a8e9-93b5-405f-a557-6296b3b6fdad'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments['flowers-infer-batch'], run_id)\n",
        "\n",
        "# Block until the run completes\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: c638a8e9-93b5-405f-a557-6296b3b6fdad\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/c638a8e9-93b5-405f-a557-6296b3b6fdad?wsid=/subscriptions/d752c461-4a37-4d63-a15d-ec58b07063cb/resourcegroups/ml-poc/workspaces/ml-poc-ws&tid=9064dc66-330c-438e-aee3-1c9e605cc16d\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'c638a8e9-93b5-405f-a557-6296b3b6fdad', 'status': 'Completed', 'startTimeUtc': '2022-05-26T15:30:27.05218Z', 'endTimeUtc': '2022-05-26T15:30:28.395376Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineid': 'caab782f-f3cb-458b-be04-5d53612f0e2b', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.c638a8e9-93b5-405f-a557-6296b3b6fdad/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Vx25ZkMD5svcA168XsZXxZG3iM72Y%2FjCadV86MXPR1k%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A20%3A37Z&se=2022-05-26T23%3A30%3A37Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.c638a8e9-93b5-405f-a557-6296b3b6fdad/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=QRa3L5PXUR%2FLkMEYZ4Au6IUP3wyE3i7qB%2FIUnewLiZM%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A20%3A37Z&se=2022-05-26T23%3A30%3A37Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlpocwsstorage21a89edcd9.blob.core.windows.net/azureml/ExperimentRun/dcid.c638a8e9-93b5-405f-a557-6296b3b6fdad/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=n91oB%2Bw6QG0Xu3gdRPrp%2BvUczykSGuta314XqbVCXi4%3D&skoid=b09f3705-4b5e-4d59-a048-37575a87eb67&sktid=9064dc66-330c-438e-aee3-1c9e605cc16d&skt=2022-05-26T08%3A31%3A01Z&ske=2022-05-27T16%3A41%3A01Z&sks=b&skv=2019-07-07&st=2022-05-26T15%3A20%3A37Z&se=2022-05-26T23%3A30%3A37Z&sp=r'}, 'submittedBy': 'Roman Kryvokhyzha'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Remove the local results folder if left over from a previous run\n",
        "shutil.rmtree('../output/predictions', ignore_errors=True)\n",
        "\n",
        "# Get the run for the first step and download its output\n",
        "prediction_run = next(pipeline_run.get_children())\n",
        "prediction_output = prediction_run.get_output_data('inferences')\n",
        "prediction_output.download(local_path='../output/predictions')\n",
        "\n",
        "# Traverse the folder hierarchy and find the results file\n",
        "for root, dirs, files in os.walk('../output/predictions'):\n",
        "    for file in files:\n",
        "        if file.endswith('parallel_run_step.txt'):\n",
        "            result_file = os.path.join(root,file)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"File\", \"Prediction\"]\n",
        "\n",
        "# Display the first 20 results\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100080576_f52e8ee070_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10140303196_b88d3d6cec.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10172379554_b296050f82_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10172567486_2748826a8b.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102841525_bd6628ae3c.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10437754174_22ec990b77_m.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10437770546_8bb6f7bdd3_m.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10437929963_bc13eebe0c.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10466558316_a7198b87e2.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10555749515_13a12a026e.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10555815624_dc211569b0.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10555826524_423eb8bf71_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10559679065_50d2b16f6d.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>105806915_a9c13e2106_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>10712722853_5632165b04.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>107592979_aaa9cdfe78_m.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10770585085_4742b9dac3_n.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10841136265_af473efc60.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10993710036_2033222c91.jpg</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10993818044_4c19b86c82.jpg</td>\n      <td>[0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                            File Prediction\n0     100080576_f52e8ee070_n.jpg        [0]\n1     10140303196_b88d3d6cec.jpg        [0]\n2   10172379554_b296050f82_n.jpg        [0]\n3     10172567486_2748826a8b.jpg        [0]\n4       102841525_bd6628ae3c.jpg        [0]\n5   10437754174_22ec990b77_m.jpg        [0]\n6   10437770546_8bb6f7bdd3_m.jpg        [0]\n7     10437929963_bc13eebe0c.jpg        [0]\n8     10466558316_a7198b87e2.jpg        [0]\n9     10555749515_13a12a026e.jpg        [0]\n10    10555815624_dc211569b0.jpg        [0]\n11  10555826524_423eb8bf71_n.jpg        [0]\n12    10559679065_50d2b16f6d.jpg        [0]\n13    105806915_a9c13e2106_n.jpg        [0]\n14    10712722853_5632165b04.jpg        [0]\n15    107592979_aaa9cdfe78_m.jpg        [0]\n16  10770585085_4742b9dac3_n.jpg        [0]\n17    10841136265_af473efc60.jpg        [0]\n18    10993710036_2033222c91.jpg        [0]\n19    10993818044_4c19b86c82.jpg        [0]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}